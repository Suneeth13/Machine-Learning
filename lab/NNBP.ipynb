{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNQE1HY1TZCysF+2OvEDjDd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"RL0bLPj9fkbR"},"outputs":[],"source":["import numpy as np\n","\n"]},{"cell_type":"code","source":["def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n"],"metadata":{"id":"Zi5RbJl2Yqzw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n"],"metadata":{"id":"N8Mug1VDYrBK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Input datasets\n","inputs = np.array([[0,0],[0,1],[1,0],[1,1]])\n","expected_output = np.array([[0],[1],[1],[0]])\n","\n","epochs = 10000\n","lr = 0.1\n","inputLayerNeurons, hiddenLayerNeurons, outputLayerNeurons = 2,2,1\n","\n"],"metadata":{"id":"Hj1JbgWPYrDn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Random weights and bias initialization\n","hidden_weights = np.random.uniform(size=(inputLayerNeurons,hiddenLayerNeurons))\n","hidden_bias =np.random.uniform(size=(1,hiddenLayerNeurons))\n","output_weights = np.random.uniform(size=(hiddenLayerNeurons,outputLayerNeurons))\n","output_bias = np.random.uniform(size=(1,outputLayerNeurons))\n","\n"],"metadata":{"id":"9L3ty7cbYrHA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training algorithm\n","for _ in range(epochs):\n","    # Forward Propagation\n","    hidden_layer_activation = np.dot(inputs, hidden_weights)\n","    hidden_layer_activation += hidden_bias\n","    hidden_layer_output = sigmoid(hidden_layer_activation)\n","\n","    output_layer_activation = np.dot(hidden_layer_output, output_weights)\n","    output_layer_activation += output_bias\n","    predicted_output = sigmoid(output_layer_activation)\n","\n","    # Backpropagation\n","    error = expected_output - predicted_output\n","    d_predicted_output = error * sigmoid_derivative(predicted_output)\n","\n","    error_hidden_layer = d_predicted_output.dot(output_weights.T)\n","    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n","\n","    # Updating Weights and Biases\n","    output_weights += hidden_layer_output.T.dot(d_predicted_output) * lr\n","    output_bias += np.sum(d_predicted_output,axis=0,keepdims=True) * lr\n","    hidden_weights += inputs.T.dot(d_hidden_layer) * lr\n","    hidden_bias += np.sum(d_hidden_layer,axis=0,keepdims=True) * lr\n"],"metadata":{"id":"O6knrMUSY_ao"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"Final hidden weights: {hidden_weights}\")\n","print(f\"Final hidden bias: {hidden_bias}\")\n","print(f\"Final output weights: {output_weights}\")\n","print(f\"Final output bias: {output_bias}\")\n","print(f\"Output from neural network after 10,000 epochs: {predicted_output}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8gtS07eHZCLZ","executionInfo":{"status":"ok","timestamp":1710427038009,"user_tz":-330,"elapsed":480,"user":{"displayName":"Suneeth S","userId":"05897375687434571539"}},"outputId":"5bfd2783-2e99-4390-b3aa-846f28e55576"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final hidden weights: [[5.69461731 3.34928039]\n"," [5.70707653 3.35131979]]\n","Final hidden bias: [[-2.27282954 -5.10171322]]\n","Final output weights: [[ 6.91007998]\n"," [-7.48610549]]\n","Final output bias: [[-3.07566583]]\n","Output from neural network after 10,000 epochs: [[0.07760158]\n"," [0.92486758]\n"," [0.92481911]\n"," [0.08366784]]\n"]}]},{"cell_type":"code","source":["'''Conclusion:This code demonstrates a simple neural network using backpropagation. It’s a basic example and doesn’t include some features you might need for more complex problems,\n","like additional hidden layers or different activation functions. However, it provides a foundation that you can build upon to create more sophisticated\n","neural networks.\n","'''\n"],"metadata":{"id":"HGqiJS3ghAof","executionInfo":{"status":"ok","timestamp":1710427159612,"user_tz":-330,"elapsed":23,"user":{"displayName":"Suneeth S","userId":"05897375687434571539"}},"outputId":"107eebc1-578f-42bc-9290-ad67d2e5f52c","colab":{"base_uri":"https://localhost:8080/","height":53}},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'Conclusion:This code demonstrates a simple neural network using backpropagation. It’s a basic example and doesn’t include some features you might need for more complex problems,\\nlike additional hidden layers or different activation functions. However, it provides a foundation that you can build upon to create more sophisticated\\nneural networks.\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]}]}